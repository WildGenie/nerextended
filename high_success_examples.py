import os
import joblib
from src.features import FeatureExtractor
from src.preprocessing import Preprocessor
from src.models.crf_model import CRFModel
import warnings
warnings.filterwarnings("ignore")

def find_high_success_paragraphs():
    # Using the No-Emb model for speed and memory stability in this environment
    model_path = "models/crf_gold_no_emb.pkl"
    if not os.path.exists(model_path):
        model_path = "/Users/wildgenie/Projects/nerextended/results/models/train_Gold__feat_use_gazetteers_use_morphology.joblib"

    model = CRFModel.load(model_path)
    config = {"use_gazetteers": True, "use_morphology": True, "use_embeddings": False}
    preprocessor = Preprocessor(engine="nuve")
    extractor = FeatureExtractor(**config)
    extractor.load_gazetteers("gazetteers")

    test_paragraphs = [
        "Manga ve Duman gruplarÄ± Ä°stanbul'da verdikleri konserde binlerce hayranÄ±yla buluÅŸtu.",
        "Hababam SÄ±nÄ±fÄ± filmi TÃ¼rk sinemasÄ±nÄ±n en deÄŸerli eseridir. RÄ±fat Ilgaz bu baÅŸarÄ±nÄ±n mimarÄ±dÄ±r.",
        "OpenAI ve Google yapay zeka alanÄ±nda rekabet ediyor.",
        "FenerbahÃ§e ve BeÅŸiktaÅŸ maÃ§Ä± yarÄ±n oynanacak.",
        "BarÄ±ÅŸ ManÃ§o'nun GÃ¼lpembe ÅŸarkÄ±sÄ± hala Ã§ok popÃ¼ler."
    ]

    print("ğŸ† BaÅŸarÄ±sÄ± YÃ¼ksek Ã–rnekler:\n")

    import nltk
    from nltk.tokenize import word_tokenize

    for text in test_paragraphs:
        tokens = word_tokenize(text)
        processed = preprocessor.process_sentence(tokens)
        feats = [extractor.sent2features(processed)]
        preds = model.predict(feats)[0]

        entities = [f"{t}({p})" for t, p in zip(tokens, preds) if p != "O"]
        print(f"ğŸ“„ Metin: {text}")
        print(f"âœ¨ Tespitler: {', '.join(entities) if entities else 'VarlÄ±k bulunamadÄ±'}")
        print("-" * 40)

if __name__ == "__main__":
    find_high_success_paragraphs()
