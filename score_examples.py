import os
import joblib
from src.features import FeatureExtractor
from src.preprocessing import Preprocessor
from src.models.crf_model import CRFModel
from nltk.tokenize import word_tokenize
import warnings
warnings.filterwarnings("ignore")

def score_specific_paragraphs():
    model_path = "models/final_model.pkl"
    if not os.path.exists(model_path):
        print("Model bulunamadÄ±.")
        return

    model = CRFModel.load(model_path)
    # Most powerful config
    config = {"use_gazetteers": True, "use_morphology": True, "use_embeddings": True}
    preprocessor = Preprocessor(engine="nuve")
    extractor = FeatureExtractor(**config)
    extractor.load_gazetteers("gazetteers")

    # Paragraphs with their expected critical entities (to calculate a success rate)
    test_suite = [
        {
            "id": "ğŸ† FenerbahÃ§e",
            "text": "FenerbahÃ§e, bu sezon ÅŸampiyonluk yarÄ±ÅŸÄ±nda iddialÄ±.",
            "expected": ["FenerbahÃ§e"]
        },
        {
            "id": "ğŸ† Titanik & Matrix",
            "text": "Titanik ve Matrix filmleri Ã§ocukluÄŸumun en unutulmaz yapÄ±mlarÄ±ydÄ±. James Cameron ve Wachowski kardeÅŸler harika iÅŸ Ã§Ä±kardÄ±.",
            "expected": ["Titanik", "Matrix", "James", "Cameron"]
        },
        {
             "id": "â„ï¸ John Snow",
             "text": "Kuzey'in kralÄ± olmanÄ±n dÄ±ÅŸÄ±nda, John Snow, Ä°ngiliz bir doktor ve anestezi uzmanÄ±dÄ±r.",
             "expected": ["John", "Snow"]
        },
        {
            "id": "ğŸ‘¤ Bill Gates",
            "text": "William Henry Gates III (28 Ekim 1955 doÄŸumlu) AmerikalÄ± bir iÅŸ insanÄ±, yazÄ±lÄ±m geliÅŸtiricisi, yatÄ±rÄ±mcÄ± ve hayÄ±rseverdir.",
            "expected": ["William", "Henry", "Gates"]
        },
        {
            "id": "ğŸ¨ Mona Lisa",
            "text": "Mona Lisa, Leonardo tarafÄ±ndan yaratÄ±lmÄ±ÅŸ 16. yÃ¼zyÄ±ldan kalma bir yaÄŸlÄ± boya tablodur. Louvre'da Paris'te sergilenmektedir.",
            "expected": ["Mona", "Lisa", "Leonardo", "Louvre", "Paris"]
        },
        {
            "id": "ğŸ† Duman & Manga",
            "text": "Duman ve Manga, TÃ¼rkiye'nin en sevilen rock gruplarÄ±ndandÄ±r. Ã–zellikle Manga, Eurovision baÅŸarÄ±sÄ±yla tanÄ±nÄ±r.",
            "expected": ["Duman", "Manga"]
        },
        {
            "id": "ğŸ† BarÄ±ÅŸ ManÃ§o",
            "text": "BarÄ±ÅŸ ManÃ§o'nun GÃ¼lpembe ÅŸarkÄ±sÄ± Ã§ok gÃ¼zel.",
            "expected": ["BarÄ±ÅŸ", "ManÃ§o"]
        },
        {
            "id": "ğŸ¢ Facebook",
            "text": "Facebook, 4 Åubat 2004'te TheFacebook olarak baÅŸlatÄ±lan bir sosyal aÄŸ hizmetidir. Mark Zuckerberg tarafÄ±ndan kurulmuÅŸtur.",
            "expected": ["Facebook", "TheFacebook", "Mark", "Zuckerberg"]
        }
    ]

    scored_results = []
    print(f"{'Ã–rnek ID':<20} | {'BaÅŸarÄ± Skoru':<15} | {'Bulunan VarlÄ±klar'}")
    print("-" * 60)

    for item in test_suite:
        tokens = word_tokenize(item["text"])
        processed = preprocessor.process_sentence(tokens)
        feats = [extractor.sent2features(processed)]
        preds = model.predict(feats)[0]

        found = []
        for t, p in zip(tokens, preds):
            if p != "O":
                found.append(t)

        # Calculate score: found expected / total expected
        expected_found = [e for e in item["expected"] if any(e in f for f in found)]
        score = len(expected_found) / len(item["expected"]) if item["expected"] else 0

        scored_results.append({
            "id": item["id"],
            "score": score,
            "found": ", ".join(found) if found else "VarlÄ±k bulunamadÄ±",
            "text": item["text"]
        })

        print(f"{item['id']:<20} | %{score*100:<13.1f} | {', '.join(found) if found else 'Yok'}")

    return scored_results

if __name__ == "__main__":
    results = score_specific_paragraphs()
    print("\nâœ… Analiz tamamlandÄ±. SkorlarÄ± 0 olan paragraflar elenebilir.")
