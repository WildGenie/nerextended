import os
import joblib
import pandas as pd
from src.features import FeatureExtractor
from src.preprocessing import Preprocessor
from src.models.crf_model import CRFModel
import warnings
warnings.filterwarnings("ignore")

def final_comparison_analysis():
    print("ğŸ”¬ Ã–rnek Metinler Ãœzerinden Model Analizi BaÅŸlatÄ±lÄ±yor...\n")

    # 1. Models to Test
    models_to_test = [
        {"name": "Bizim En Ä°yi Model (Best)", "path": "models/crf_gold_best.pkl", "config": {"use_gazetteers": True, "use_morphology": True, "use_embeddings": True}},
        {"name": "Orta Seviye (No Emb)", "path": "models/crf_gold_no_emb.pkl", "config": {"use_gazetteers": True, "use_morphology": True, "use_embeddings": False}},
        {"name": "Temel Seviye (Gaz Only)", "path": "models/crf_gold_gaz_only.pkl", "config": {"use_gazetteers": True, "use_morphology": False, "use_embeddings": False}},
    ]

    # 2. Example Texts
    examples = {
        "Duman & Manga": "Duman ve Manga, TÃ¼rkiye'nin en sevilen rock gruplarÄ±ndandÄ±r. Ã–zellikle Manga, Eurovision baÅŸarÄ±sÄ±yla tanÄ±nÄ±r.",
        "Titanik & Matrix": "Titanik ve Matrix filmleri Ã§ocukluÄŸumun en unutulmaz yapÄ±mlarÄ±ydÄ±. James Cameron ve Wachowski kardeÅŸler harika iÅŸ Ã§Ä±kardÄ±.",
        "FenerbahÃ§e": "FenerbahÃ§e, bu sezon ÅŸampiyonluk yarÄ±ÅŸÄ±nda iddialÄ±.",
        "OpenAI & Google": "OpenAI yapay zeka alanÄ±nda devrim yarattÄ±. Google ise kendi dil modelleriyle rekabete dahil oldu.",
        "Bill Gates": "William Henry Gates III (28 Ekim 1955 doÄŸumlu) AmerikalÄ± bir iÅŸ insanÄ±, yazÄ±lÄ±m geliÅŸtiricisi, yatÄ±rÄ±mcÄ± ve hayÄ±rseverdir.",
        "Mona Lisa": "Mona Lisa, Leonardo tarafÄ±ndan yaratÄ±lmÄ±ÅŸ 16. yÃ¼zyÄ±ldan kalma bir yaÄŸlÄ± boya tablodur. Louvre'da Paris'te sergilenmektedir.",
        "John Snow": "Kuzey'in kralÄ± olmanÄ±n dÄ±ÅŸÄ±nda, John Snow, Ä°ngiliz bir doktor ve anestezi uzmanÄ±dÄ±r.",
        "BarÄ±ÅŸ ManÃ§o": "BarÄ±ÅŸ ManÃ§o'nun GÃ¼lpembe ÅŸarkÄ±sÄ± Ã§ok gÃ¼zel."
    }

    import nltk
    try: nltk.data.find('tokenizers/punkt')
    except: nltk.download('punkt')
    from nltk.tokenize import word_tokenize

    preprocessor = Preprocessor(engine="nuve")

    # 3. Execution
    for title, text in examples.items():
        print(f"\nğŸ“Œ Ã–rnek: {title}")
        print(f"ğŸ“„ Metin: {text}")
        print("-" * 30)

        comparison_data = []
        tokens = word_tokenize(text)
        processed = preprocessor.process_sentence(tokens)

        for m_info in models_to_test:
            if not os.path.exists(m_info["path"]):
                continue

            try:
                model = CRFModel.load(m_info["path"])
                extractor = FeatureExtractor(**m_info["config"])
                extractor.load_gazetteers("gazetteers")

                feats = [extractor.sent2features(processed)]
                preds = model.predict(feats)[0]

                # Extract entities only for cleaner look
                entities = []
                for t, p in zip(tokens, preds):
                    if p != "O":
                        entities.append(f"{t}({p})")

                comparison_data.append({
                    "Model": m_info["name"],
                    "Tespit Edilen VarlÄ±klar": ", ".join(entities) if entities else "VarlÄ±k bulunamadÄ±"
                })
            except Exception as e:
                comparison_data.append({"Model": m_info["name"], "Tespit Edilen VarlÄ±klar": f"Hata: {e}"})

        df = pd.DataFrame(comparison_data)
        print(df.to_string(index=False))
        print("=" * 80)

if __name__ == "__main__":
    final_comparison_analysis()
